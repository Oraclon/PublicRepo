Ah, I see! You're asking about a scenario where the previous layer has a feature map of shape 
3
×
3
×
64
3×3×64 (a 
3
×
3
3×3 spatial size with 64 channels), and you're passing it to the next convolutional layer with a filter of shape 
3
×
3
×
128
3×3×128 (again, a 
3
×
3
3×3 spatial size but with 128 output channels).

Let's break this down:

Scenario:
Previous layer output: 
3
×
3
×
64
3×3×64

This means the feature map from the previous layer has 64 channels (depth), and each channel is a 
3
×
3
3×3 feature map.

Next convolutional layer: A filter of shape 
3
×
3
×
128
3×3×128

This means you are using 128 filters (each of size 
3
×
3
×
64
3×3×64, since the depth of each filter matches the depth of the previous layer’s output, i.e., 64).

Now, let's discuss how this works and address the concern about the sum of responses and how large filters affect the computation.

Understanding the Operation:
Filter Shape:

You have 128 filters, each of size 
3
×
3
×
64
3×3×64. This means each filter looks at the full depth (64 channels) of the previous layer. For each filter, the convolution operation involves performing a dot product between the filter and the corresponding region in the 
3
×
3
×
64
3×3×64 feature map from the previous layer.

So, each filter is applied across all 64 channels, resulting in a single scalar output per spatial position.

Output Feature Map:

After applying each of the 128 filters, you will obtain 128 output channels. So, the output feature map from this layer will have dimensions 
1
×
1
×
128
1×1×128, assuming the stride is 1 and there is no padding. In essence, you're going from a 
3
×
3
×
64
3×3×64 feature map to a 
1
×
1
×
128
1×1×128 feature map (if you're using valid padding, i.e., no padding).

If you have padding (e.g., same padding), the output feature map size may be larger.

Effect of Bias:

Each of the 128 filters will have one bias term. So, each filter’s output is shifted by the corresponding bias term.

The bias does not increase with filter size—each filter simply adds a single scalar bias to its output feature map. So, in total, you have 128 biases for this layer (one for each filter).

Summing the Responses:

You will have 128 distinct feature maps as a result of the 128 filters. These are not summed together directly but are rather passed through activation functions (e.g., ReLU) and potentially combined in later layers.

Each filter contributes a separate output feature map, which might be used individually or in combination with other feature maps in subsequent layers (depending on the network architecture).

Summary of the Calculation:
Input: 
3
×
3
×
64
3×3×64 (from the previous layer).

Filter: 
3
×
3
×
64
3×3×64 with 128 filters.

Output: After the convolution, you'll get 128 feature maps, each with a size of 
1
×
1
1×1 (assuming no padding and stride of 1). The output tensor will be 
1
×
1
×
128
1×1×128 after this layer.

Key Points:
Each filter has one bias, and that bias is applied to the entire feature map produced by that filter.

The responses of the filters are not summed. Instead, they are stored as separate feature maps in the output tensor.

Larger filters (in terms of the number of filters) increase the number of output channels but do not affect the biases of the individual filters. In your case, you would have 128 biases—one for each of the 128 filters, not one for each spatial location.

If you're asking about how large filters (in terms of the number of filters) affect the magnitude of the output, the output might have larger values (due to the increased number of filters), but this is managed through training (via gradient descent, for example). The biases remain separate from the summed feature map responses.
